{"cells":[{"cell_type":"markdown","source":["## Utils"],"metadata":{"id":"9uyJruaNvlj7"}},{"cell_type":"code","source":["\n","import tensorflow as tf\n","import keras\n","import os\n","import re\n","import glob\n","import numpy as np\n","import cv2\n","\n","\"\"\"**Dicionário RGB > Rótulo**\"\"\"\n","def gen_dict_cores():\n","    mask_dict = {\n","        (0, 0, 0): 0,        # Preto = None\n","        (100, 0, 100): 1,    # Violeta = Liver (fígado)\n","        (255, 255, 255): 2,  # Branco = Bone (Osso)\n","        (0, 255, 0): 3,      # Verde = Gallbladder (Vesícula biliar)\n","        (255, 255, 0): 4,    # Amarelo = Kidney (Rins)\n","        (0, 0, 255): 5,      # Azul = Pancreas\n","        (255, 0, 0): 6,      # Vermelho = Vessels (Veias)\n","        (255, 0, 255): 7,    # Rosa = Spleen (Baço)\n","        (0, 255, 255): 8     # Azul claro = Adrenal (Glândula Adrenal)\n","    }\n","    return mask_dict\n","\n","\"\"\" Função que mapeia cada pixel da imagem ao valor rgb definido no dicionário,\n"," e substitui o valor pelo rótulo correspondente, em um novo array.\"\"\"\n","\n","def RGBtoClass(rgb, dictCores):\n","    arr = np.zeros(rgb.shape[:2])  # Inicializa a matriz de rótulos\n","\n","    for color, label in dictCores.items():  # Itera sobre os pares (cor, rótulo)\n","        color = np.array(color)  # Converte a cor para um array NumPy\n","        arr[np.all(rgb == color, axis=-1)] = label  # Atribui o rótulo aos pixels que correspondem à cor\n","\n","    return arr\n","\n","def onehot_to_rgb(oneHot, dictCores):\n","    oneHot = np.array(oneHot)  # Converte para array numpy\n","    oneHot = np.argmax(oneHot, axis=-1)  # Seleciona o maior valor (índice)\n","    output = np.zeros(oneHot.shape + (3,))  # Cria a matriz RGB de saída\n","    oneHot = np.expand_dims(oneHot, axis=-1)  # Expande as dimensões\n","\n","    for color, index in dictCores.items():\n","        output[np.all(oneHot == index, axis=-1)] = color\n","\n","    return np.uint8(output)\n","\n","\"\"\"esta função segmenta o nome do arquivo para o img_loader ordenar o dataset\n","na ordem do diretório e ter correspondência entre a lista de imagens e máscaras\"\"\"\n","\n","def natural_sort_key(s):\n","    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n","\n","\"\"\" img_loader recebe um caminho de diretório,uma lista vazia e  uma tupla com\n","dimensões de imagem. Lê as imagens png ou jpg do diretório, ordena pelo nome e\n"," armazena a imagem na lista img_data e seu nome na lista img_names\"\"\"\n","def img_loader(path, img_data, size=None, rgb=True):\n","  #lista para o nome dos arquivos\n","  img_names = []\n","\n","  for diretorio_path in sorted(glob.glob(path)):\n","    for img_path in sorted(glob.glob(os.path.join(diretorio_path, \"*.[pj]*[np]*[g]*\")), key=natural_sort_key): #percorre o diretório na ordem natural dos títulos de arquivo\n","      img = cv2.imread(img_path,\n","                       cv2.IMREAD_COLOR if rgb\n","                       else cv2.IMREAD_GRAYSCALE) #img tem 3 canais na 3 dimensao se RGB, e 1 canal se preto/branco\n","\n","      if rgb:  # Corrige para formato RGB\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      if size is not None:\n","        img = cv2.resize(img, size) #redimensiona conforme o parâmetro\n","\n","      img_data.append(img.astype(np.uint8)) #add a imagem na lista do parametro\n","      img_names.append(os.path.basename(img_path)) #add o nome do arquivo na lista de nomes\n","\n","  #return img_data, img_names\n","  return np.array(img_data), img_names\n","\n","def save_dataset(X_train, X_val, X_test, y_train, y_val, y_test, save_dir=\"dataset\"):\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    np.save(os.path.join(save_dir, \"X_train.npy\"), X_train)\n","    np.save(os.path.join(save_dir, \"X_val.npy\"), X_val)\n","    np.save(os.path.join(save_dir, \"X_test.npy\"), X_test)\n","    np.save(os.path.join(save_dir, \"y_train.npy\"), y_train)\n","    np.save(os.path.join(save_dir, \"y_val.npy\"), y_val)\n","    np.save(os.path.join(save_dir, \"y_test.npy\"), y_test)\n","\n","    print(f\"Dataset salvo em {save_dir}\")\n","\n","def load_dataset(save_dir=\"dataset\"):\n","\n","    X_train = np.load(os.path.join(save_dir, \"X_train.npy\"))\n","    X_val = np.load(os.path.join(save_dir, \"X_val.npy\"))\n","    X_test = np.load(os.path.join(save_dir, \"X_test.npy\"))\n","    y_train = np.load(os.path.join(save_dir, \"y_train.npy\"))\n","    y_val = np.load(os.path.join(save_dir, \"y_val.npy\"))\n","    y_test = np.load(os.path.join(save_dir, \"y_test.npy\"))\n","\n","    print(f\"Dataset carregado de {save_dir}\")\n","    return X_train, X_val, X_test, y_train, y_val, y_test"],"metadata":{"id":"xd-awO0Mvoo2","executionInfo":{"status":"ok","timestamp":1738956297374,"user_tz":180,"elapsed":13,"user":{"displayName":"davi bezerra","userId":"17273633987948576903"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"XqRQJYpkvPVL"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import Model\n","\n","# Bloco convolucional utilizado em todas as etapas\n","def ConvBlock(tensor, num_feature):\n","\n","  x = tf.keras.layers.Conv2D(num_feature, (3,3), activation='relu', kernel_initializer='he_normal',padding='same')(tensor)\n","  x = tf.keras.layers.BatchNormalization()(x)\n","  x = tf.keras.layers.Dropout(0.1)(x)\n","  x = tf.keras.layers.Conv2D(num_feature, (3,3), activation='relu', kernel_initializer='he_normal',padding='same')(x)\n","  x = tf.keras.layers.BatchNormalization()(x)\n","\n","  return x\n","\n","def ponte(tensor, num_feature):\n","  x = ConvBlock(tensor,num_feature)\n","  return x\n","\n","# Seção encoder\n","def encoder_block(tensor, num_feature):\n","  x = ConvBlock(tensor, num_feature)\n","  p = tf.keras.layers.MaxPooling2D((2,2))(x)\n","  return x, p\n","\n","#seção decoder\n","def decoder_block(tensor,skip_connection, num_feature):\n","  x = tf.keras.layers.Conv2DTranspose(num_feature, (2,2), strides=(2,2), padding='same')(tensor) #recebe do bloco anterior e faz upsampling\n","  x = tf.keras.layers.concatenate([x, skip_connection])\n","  x = ConvBlock(x, num_feature)\n","  return x\n","\n","\"\"\"### estrutura da u-net\"\"\"\n","\n","def Unet(n_classes, tensor_shape):\n","\n","  input = tf.keras.layers.Input(tensor_shape) #instancia o tensor para os dados de entrada\n","\n","  #seção de contração:\n","  skip1, c1 = encoder_block(input,16) # 128x128x3 > 64x64x16\n","  skip2, c2 = encoder_block(c1,32) # 64x64x16 > 32x32x32\n","  skip3, c3 = encoder_block(c2,64) # 32x32x32 > 16x16x64\n","  skip4, c4 = encoder_block(c3,128) # 16x16x64 > 8x8x64\n","\n","  #bottleneck\n","  c5 = ponte(c4,256) # 8x8x64 > 8x8x256\n","\n","  #seção de expansão:\n","  c6 = decoder_block(c5, skip4, 128) #8x8x256 > 16x16x128\n","  c7 = decoder_block(c6, skip3, 64) #16x16x128 > 32x32x64\n","  c8 = decoder_block(c7, skip2, 32) #32x32x64 > 64x64x32\n","  c9 = decoder_block(c8, skip1, 16) #64x64x32 > 128x128x16\n","\n","  #camada de saída:\n","  output = tf.keras.layers.Conv2D(n_classes, (1,1), activation='softmax')(c9) #128x128x16 > 128x128x8, 8= número de classes\n","\n","  model = Model(input, output, name=\"U-Net\")\n","  return model"],"metadata":{"id":"dWk94WUAvOq7","executionInfo":{"status":"ok","timestamp":1738956297392,"user_tz":180,"elapsed":11,"user":{"displayName":"davi bezerra","userId":"17273633987948576903"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"etfxAeatvbO-"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from utils import img_loader, save_dataset, RGBtoClass, gen_dict_cores\n","from sklearn.utils import class_weight\n","\n","# caminhos para os diretórios das imagens\n","\n","real_img_treino = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/abdominal_US/RUS/images/train\"\n","# não tem mascara de treino pra ultrasons reais\n","sim_img_treino = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/AUS/images/train\"\n","sim_mask_treino = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/AUS/annotations/train\"\n","\n","real_img_val = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/abdominal_US/RUS/images/test\"\n","#real_mask_val = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/abdominal_US/RUS/annotations/test\"\n","sim_img_val = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/AUS/images/test\"\n","sim_mask_val = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data/abdominal_US/AUS/annotations/test\"\n","\n","\n","#conjuntos de treino\n","  #imagens simuladas\n","Simg_treino = []\n","Simg_treino_names = []\n","Smask_treino = []\n","Smask_treino_names = []\n","  #imagens reais\n","\"\"\"Rimg_treino = []\n","Rimg_treino_names = []\n","#ñ tem mascara real p teste\"\"\"\n","\n","#conjuntos de teste\n","  #imagens simuladas\n","Simg_val = []\n","Simg_val_names = []\n","Smask_val = []\n","Smask_val_names = []\n","\n","  #imagens reais\n","\"\"\"Rimg_val = []\n","Rimg_val_names = []\n","Rmask_val = []\n","Rmask_val_names = []\"\"\"\n","\n","#Carregando os dados:\n","\n","dim = (256,256)\n","Simg_treino, Simg_treino_names = img_loader(sim_img_treino, Simg_treino,dim, False)\n","Smask_treino, Smask_treino_names = img_loader(sim_mask_treino,Smask_treino,dim)\n","#Rimg_treino, Rimg_treino_names = img_loader(real_img_treino,Rimg_treino,None,False)\n","\n","Simg_val, Simg_val_names = img_loader(sim_img_val, Simg_val,dim, False)\n","Smask_val, Smask_val_names = img_loader(sim_mask_val,Smask_val,dim)\n","#Rimg_val, Rimg_val_names = img_loader(real_img_val, Rimg_val,None,False)\n","#Rmask_val, Rmask_val_names = img_loader(real_mask_val,Rmask_val)\n","\n","'''concatenando as imagens e mascaras de treino / teste para separar ao carregar\n","no  train_test_split'''\n","all_imgs = np.concatenate((Simg_treino, Simg_val), axis=0)\n","all_masks = np.concatenate((Smask_treino, Smask_val), axis=0)\n","\n","all_imgname = Simg_treino_names + Simg_val_names\n","all_maskname = Smask_treino_names + Smask_val_names\n","\n","all_imgs  = np.expand_dims(all_imgs, axis=3)\n","#all_imgs.shape, all_masks.shape\n","\n","\"\"\"**Convertendo máscaras**\"\"\"\n","\n","dictCores = gen_dict_cores()\n","all_mask_class = []\n","\n","for mask in  all_masks:\n","    onehotmask = RGBtoClass(mask, dictCores)\n","    all_mask_class.append(onehotmask)\n","\n","all_mask_class = np.array(all_mask_class)\n","all_mask_class = np.expand_dims(all_mask_class, axis=3)\n","\n","print(\"Classes únicas nos pixels das  máscaras :\", np.unique(all_mask_class), all_mask_class.shape)\n","\n","\"\"\"**Divisão do dataset em conjuntos de treino , validação e teste**\n","\n","\n","\"\"\"\n","\n","# Divisão inicial: 10% para teste e 90% para treino e validação\n","X_train_val, X_test, y_train_val, y_test = train_test_split(\n","    all_imgs, all_mask_class, test_size=0.1, random_state=0, shuffle=False\n",")\n","\n","# Segunda divisão: 15% para validação e 85% para teste\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train_val, y_train_val, test_size=0.15, random_state=0, shuffle=False\n",")\n","\n","# tamanhos dos conjuntos\n","print(f\"Treino: {len(X_train)}, Validação: {len(X_val)}, Teste: {len(X_test)}\")\n","\n","#normalizando os conjuntos\n","X_train = X_train.astype('float32') / 255.0\n","X_val = X_val.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","y_train = y_train.astype(np.int32)\n","y_val = y_val.astype(np.int32)\n","y_test = y_test.astype(np.int32)\n","\n","# Salvando os dados\n","save_dataset(X_train, X_val, X_test, y_train, y_val, y_test, save_dir = \"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data\")\n","\n","\"\"\"retorna X_train,\n","\n"," pq o collab ta colapsando de tanta coisa na RAM\n","\"\"\"\n","\n","\"\"\"\n","class_weights_array = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n","class_weights = {i: class_weights_array[i] for i in range(len(class_weights_array))}\n"," \"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"Hk-ECGCtvdLj","executionInfo":{"status":"ok","timestamp":1733335351138,"user_tz":180,"elapsed":117294,"user":{"displayName":"davi bezerra","userId":"17273633987948576903"}},"outputId":"f39bfb6d-7e35-4ecb-8daa-2bf1b2364b77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes únicas nos pixels das  máscaras : [0. 1. 2. 3. 4. 5. 6. 7. 8.] (926, 256, 256, 1)\n","Treino: 708, Validação: 125, Teste: 93\n","Dataset salvo em /content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal\n"]},{"output_type":"execute_result","data":{"text/plain":["\" \\nclass_weights_array = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\\nclass_weights = {i: class_weights_array[i] for i in range(len(class_weights_array))}\\n \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Metrics"],"metadata":{"id":"3PRH2NSR1hka"}},{"cell_type":"code","source":["# Evaluation metrics: dice coefficient\n","def dice_coef(y_true, y_pred, smooth = 1.):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","\n","# Evaluation metrics: iou\n","def iou(y_true, y_pred, smooth = 1.):\n","    intersection = K.sum(y_true * y_pred)\n","    sum_ = K.sum(y_true) + K.sum(y_pred)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return jac\n","\n","\n","# Definição da função de perda Jaccard\n","def jaccard_distance_loss(y_true, y_pred, smooth=100):\n","    \"\"\"\n","    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n","            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n","\n","    Jaccard Distance Loss é útil para datasets desbalanceados.\n","    \"\"\"\n","    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n","    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n","\n","    intersection = tf.reduce_sum(tf.abs(y_true * y_pred), axis=-1)\n","    sum_ = tf.reduce_sum(tf.abs(y_true) + tf.abs(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return (1 - jac) * smooth\n","\n","\n","### Monitoramentto de IOU no treino\n","class IoUCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        y_pred = self.model.predict(self.validation_data[0])\n","        y_pred_argmax = np.argmax(y_pred, axis=-1).astype(np.int32)\n","        iou = MeanIoU(num_classes=num_classes)\n","        iou.update_state(self.validation_data[1], y_pred_argmax)\n","        print(f\"Epoch {epoch + 1} - Mean IoU: {iou.result().numpy()}\")\n"],"metadata":{"id":"njq635na1k5o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training_Eval\n"],"metadata":{"id":"gmN_JLsLv75y"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras import backend as K\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from utils import save_dir\n","from model import Unet\n","\n","##  Compilando #################################################################\n","\n","#parâmetros:\n","input_shape = (256,256, 1)\n","num_classes = 9\n","lr = 0.003\n","#metrics = [\"accuracy\",MeanIoU(num_classes=num_classes)]\n","metrics = [\"accuracy\"]\n","loss =  SparseCategoricalCrossentropy()\n","#loss = 'categorical_crossentropy'\n","#loss = jaccard_distance_loss(y_test, y_pred).numpy()\n","\n","model = Unet(num_classes, input_shape)\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=loss, metrics=metrics)\n","model.summary()\n","\n","\n","## Treinamento #################################################################\n","\n","\n","# Carregar os dados\n","X_train, X_val, X_test, y_train, y_val, y_test = load_dataset(save_dir=\"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data\")\n","\n","#y_train_cat = to_categorical(y_train, num_classes = 9)\n","#y_val_cat = to_categorical(y_val, num_classes = 9)\n","#y_test_cat = to_categorical(y_val, num_classes = 9)\n","\n","## Data augmentation  ======================================\n","\n","image_gen = ImageDataGenerator(\n","    rotation_range=15,            # Rotação aleatória de até 15 graus\n","    width_shift_range=0.3,        # Translação horizontal de até 30%\n","    height_shift_range=0.3,       # Translação vertical de até 30%\n","    shear_range=5,                # Cisalhamento de até 5%\n","    horizontal_flip=True,         # Flip horizontal\n","    vertical_flip=True,           # Flip vertical\n","    fill_mode='nearest',          # Preenchimento de regiões em branco após transformação\n","    brightness_range=[0.9, 1.1],  # Ajuste aleatório de brilho (80% a 120% do valor original)\n","    )\n","\n","'''Mesmas transformações para as máscaras, exceto o brilho\n","para não afetar os valores das classes'''\n","\n","mask_gen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=5,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest'\n","    )\n","\n","#ajustando os geradores para as imagens\n","image_gen.fit(X_train, augment=True)\n","mask_gen.fit(y_train, augment=True)\n","\n","# Instanciando os geradores para mascaras e imagens\n","image_generator = image_gen.flow(X_train, batch_size=32, seed=42)\n","mask_generator = mask_gen.flow(y_train, batch_size=32\n",", seed=42)\n","\n","# Combinando os geradores para gerar lotes com as mesmas transformações\n","train_generator = zip(image_generator, mask_generator)\n","def augmenteixons():\n","    for img, mask in train_generator:\n","        yield img, mask\n","\n","## treinamento sem augmentation ============================\n","\n","#Parâmetros p/ callbacks\n","model_name = 'Jaccard01'\n","arquivo_modelo = f'/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Modelos/modelo_{model_name}.keras' # .h não é mais aceito\n","arquivo_modelo_json = f'/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Modelos/modelo_{model_name}.json'\n","\n","#Callbacks\n","lr_reducer = ReduceLROnPlateau( monitor='val_loss', factor = 0.9, patience = 3, verbose = 1)\n","early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience = 15, verbose = 1, mode='auto')\n","checkpointer = ModelCheckpoint(arquivo_modelo, monitor = 'val_loss', verbose = 1, save_best_only=True)\n","\n","\n","history = model.fit(X_train, y_train_cat,\n","                    batch_size=16,\n","                    verbose=1,\n","                    epochs = 100,\n","                    validation_data=(X_val, y_val_cat),\n","                    callbacks=[lr_reducer, early_stopper, checkpointer,IoUCallback()],\n","                    shuffle=False)\n","\n","## Treinamento com augmentation ========================\n","'''\n","history = model.fit(augmenteixons(),\n","                    steps_per_epoch=len(X_train) // 32,\n","                    verbose=1,\n","                    epochs = 100,\n","                    validation_data=(X_val, y_val),\n","                    callbacks=[ checkpointer],\n","                    shuffle=False) '''\n","\n","\"\"\"##Avaliação\"\"\"\n","\n","_, acc = model.evaluate(X_test, y_test)\n","print(\"Accuracy is = \", (acc * 100.0), \"%\")\n","\n","##Plota a loss e accuracy de treino e validação a acda época\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'y', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.plot(epochs, acc, 'y', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Training and validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"FxE6jlmxv9SZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Test save"],"metadata":{"id":"Z5kH2hwWw167"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","from keras.models import load_model\n","from keras.metrics import MeanIoU\n","from keras.utils import to_categorical\n","from utils import gen_dict_cores, onehot_to_rgb, load_dataset\n","import cv2\n","\n","model_name = 'Aug02'\n","model = load_model(f'Modelos/modelo_{model_name}.keras')\n","# Carregar os dados\n","X_train, X_val, X_test, y_train, y_val, y_test = load_dataset(save_dir=\"/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Data\")\n","\n","print(\"X_val shape:\", X_val.shape)\n","print(\"y_val shape:\", y_val.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","#predição do conjunto de teste\n","y_pred=model.predict(X_test)\n","y_pred_argmax=np.argmax(y_pred, axis=3)\n","\n","####### avaliando pela metrica \"intersection over union\" no conjunto de teste ##\n","from keras.metrics import MeanIoU\n","n_classes = 9\n","IOU_keras = MeanIoU(num_classes=n_classes)\n","IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n","\n","print(\"Mean IoU TESTE =\", IOU_keras.result().numpy())\n","\n","###### Salvando todas as predições ##################################\n","\n","testename = \"Teste5\"\n","output_dir = f'Testes/{testename}'\n","os.makedirs(output_dir, exist_ok=True)  # Cria o diretório, se não existir\n","dictCores = gen_dict_cores()\n","\n","# Itera sobre todo o conjunto de teste\n","for idx in range(len(X_test)):\n","    # Seleciona a imagem, a máscara e a predição correspondentes\n","    img = X_test[idx]\n","    mask = y_test[idx]\n","    pred = y_pred[idx]\n","\n","    # Cria o plot\n","    plt.figure(figsize=(12, 4))\n","\n","    # Imagem original\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(img, cmap='gray')\n","    plt.title(\"Imagem Original\")\n","    plt.axis('off')\n","\n","    # Máscara\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(onehot_to_rgb(to_categorical(mask, num_classes=9), dictCores))\n","    plt.title(\"Ground Truth\")\n","    plt.axis('off')\n","\n","    # Predição\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(onehot_to_rgb(pred, dictCores), cmap='gray')\n","    plt.title(\"Predição\")\n","    plt.axis('off')\n","\n","    # Salva o plot no diretório\n","    output_path = os.path.join(output_dir, f\"plot_{idx}.png\")\n","    plt.savefig(output_path, bbox_inches='tight')\n","    plt.close()\n","\n","print(f\"Todas as imagens foram salvas em: {output_dir}\")"],"metadata":{"id":"iuRZ88vzw5I6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## App_segmentador\n"],"metadata":{"id":"SSJ1xh9sw_di"}},{"cell_type":"code","source":["\n","import numpy as np\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import gradio as gr\n","from tensorflow.keras.models import load_model\n","\n","modelname = \"modelo_01_UnetUS\"\n","model = load_model(f'/content/drive/MyDrive/Colab Notebooks/Segementação_Abdominal/Modelos/{modelname}.keras')\n","\n","def gen_dict_cores_labels():\n","    mask_dict = {\n","        (0, 0, 0): (0, \"Fundo\"),             # Preto = None\n","        (100, 0, 100): (1, \"Figado\"),        # Violeta = Liver (fígado)\n","        (255, 255, 255): (2, \"Osso\"),       # Branco = Bone (Osso)\n","        (0, 255, 0): (3, \"Vesicula biliar\"),    # Verde = Gallbladder (Vesícula biliar)\n","        (255, 255, 0): (4, \"Rim\"),       # Amarelo = Kidney (Rins)\n","        (0, 0, 255): (5, \"Pancreas\"),       # Azul = Pancreas\n","        (255, 0, 0): (6, \"Veia\"),        # Vermelho = Vessels (Veias)\n","        (255, 0, 255): (7, \"Baço\"),       # Rosa = Spleen (Baço)\n","        (0, 255, 255): (8, \"Gland. Adrenal\")       # Azul claro = Adrenal (Glândula Adrenal)\n","    }\n","    return mask_dict\n","\n","# Função para converter de one-hot para RGB e identificar classes\n","def onehot_to_rgb_labels(oneHot, dictCoresLabels):\n","    oneHot = np.array(oneHot)\n","    oneHot = np.argmax(oneHot, axis=-1)\n","    output = np.zeros(oneHot.shape + (3,))  # Cria a matriz RGB de saída\n","    present_classes = set()\n","\n","    for color, (_, label) in dictCoresLabels.items():\n","        mask = oneHot == _\n","        output[mask] = color\n","        if np.any(mask):\n","            present_classes.add(label)\n","\n","    return np.uint8(output), list(present_classes)\n","\n","# Função para criar legenda em HTML com nomes e cores\n","def create_legend_html(present_labels, dictCoresLabels):\n","    legend_html = \"<ul style='list-style-type:none; padding:0;'>\"\n","    for color, (_, label) in dictCoresLabels.items():\n","        if label in present_labels:\n","            color_hex = f\"rgb{color}\"  # Converte a cor para o formato RGB\n","            legend_html += f\"<li style='color:{color_hex}; font-weight:bold;'>{label}</li>\"\n","    legend_html += \"</ul>\"\n","    return legend_html\n","\n","def predictmask_legend(image):\n","    dictCoresLabels = gen_dict_cores_labels()\n","\n","    original_size = image.size\n","    image_resized = preprocess_image(image)\n","\n","    y_pred = model.predict(image_resized)\n","    y_pred = y_pred[0]\n","\n","    # Converte a predição para RGB e identifica os rótulos\n","    y_pred_rgb, labels = onehot_to_rgb_labels(y_pred, dictCoresLabels)\n","\n","    # Redimensiona a máscara para o tamanho original da imagem\n","    y_pred_resized = cv2.resize(y_pred_rgb, original_size, interpolation=cv2.INTER_NEAREST)\n","    image_original_rgb = image.convert(\"RGB\")\n","\n","    # Combina a imagem original com a máscara\n","    alpha = 0.9\n","    beta = 0.5\n","    image_combined = cv2.addWeighted(np.array(image_original_rgb), beta, y_pred_resized, alpha, 0)\n","    legend_html = create_legend_html(labels, dictCoresLabels) #gera legenda\n","\n","    return Image.fromarray(np.uint8(image_combined)), legend_html\n","\n","def preprocess_image(image):\n","\n","    image_resized = cv2.resize(np.array(image), (256, 256))\n","    image_resized = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n","\n","    # Normaliza e add batchdim\n","    image_resized = image_resized.astype('float32') / 255.0\n","    image_resized = np.expand_dims(image_resized, axis=0)\n","\n","    # Adiciona uma dimensão extra p/ canal de cor\n","    image_resized = np.expand_dims(image_resized, axis=-1)\n","\n","    return image_resized\n","\n","# Interface Gradio\n","interface = gr.Interface(\n","    fn=predictmask_legend,   # Função para predição e legendas\n","    inputs=gr.Image(type=\"pil\", label=\"Carregue uma imagem\"),  # Entrada de imagem\n","    outputs=[\n","        gr.Image(type=\"pil\", label=\"Imagem Segmentada\"),  # Saída da imagem com sobreposição\n","        gr.HTML(label=\"Legenda dos Órgãos Detectados\")                # Saída em HTML para legenda colorida\n","    ],\n","    title=\"Segmentador de Ultrassom Abdominal\",         # Título da interface\n","    description=\"Carregue uma ultrassonografia de cavidade abdominal para identificar os órgãos.\"\n",")\n","\n","interface.launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":612},"id":"nVqJUIW-xFIo","executionInfo":{"status":"ok","timestamp":1733335010566,"user_tz":180,"elapsed":4365,"user":{"displayName":"davi bezerra","userId":"17273633987948576903"}},"outputId":"e7b9d73d-b0a8-4287-f4af-a8af2594b67e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://561a86df01b45659f3.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://561a86df01b45659f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xh3irzSTzsUE","executionInfo":{"status":"ok","timestamp":1733334869309,"user_tz":180,"elapsed":14893,"user":{"displayName":"davi bezerra","userId":"17273633987948576903"}},"outputId":"37a1f45c-183b-43f3-9b5f-38a05e127470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.5.0 (from gradio)\n","  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Collecting markupsafe~=2.0 (from gradio)\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart==0.0.12 (from gradio)\n","  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.0->gradio) (2024.10.0)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.5.0->gradio)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.7.1-py3-none-any.whl (57.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.5.0-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n","Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.4.0 gradio-5.7.1 gradio-client-1.5.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Mp7kIKWAzsD2"}}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["9uyJruaNvlj7","XqRQJYpkvPVL"],"toc_visible":true,"gpuType":"T4","mount_file_id":"1BznfENloy82Y3j66sxlG83ELzadSjn8m","authorship_tag":"ABX9TyPzBK7QPvCBeBXA4kS9ai+3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}